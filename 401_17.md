# Code 401 - Class 17

## Web scraping

It would be nice if all the data we ever wanted was available to us from easy to use APIs, with clean documentation, delivering us all of our desires in crisp JSON and lovely csv files. But alas, the real world wide web is not so obliging. Enter web scraping.

With web scraping, we can extract data from the html structure of web sites (given that these sites have scraping friendly terms of service). For any budding data science, web scraping is a necessary skill to develop.

These days, helpful web scraping libraries are available like Beautiful Soup and Selenium Webdriver. With these tools, we can automate the collection of large troves of data structures with relatively short scripts.

The general process of web scraping is to identify which html elements on a given page hold the desired data, target these elements using their CSS selectors and a library like Beautiful Soup, download all the matching elements, and process their content. An important consideration is to instruct your crawler to pause for sufficient intervals between downloading files from a given site so that it is not spammed with requests.

## Strategies to scrape websites without getting blocked

- Follow the directions of the robots.txt files
- Make sure your crawler is set up to sleep for a few seconds between requests or 10-20 seconds between clicks. You can also set your crawler to throttle requests if the website is experiencing high loads.
- Follow different crawling patterns
- Make requests through proxies
  - These could be VPNs, private proxies, etc
- Rotate user agents and request headers
- Use a webdriver like Selenium
